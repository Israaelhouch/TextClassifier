{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be3ed458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c59ba67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Remove punctuation, numbers, special chars\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # 4. Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    # 5. Join back to string\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "292120de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and encoder\n",
    "with open(r\"C:\\Users\\lenovo\\Desktop\\classifiction project\\model\\news_classifier.pkl\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open(r\"C:\\Users\\lenovo\\Desktop\\classifiction project\\model\\label_encoder.pkl\", \"rb\") as le_file:\n",
    "    le = pickle.load(le_file)\n",
    "\n",
    "# Load the TF-IDF vectorizer too, if you saved it:\n",
    "with open(r\"C:\\Users\\lenovo\\Desktop\\classifiction project\\model\\tfidf_vectorizer.pkl\", \"rb\") as vec_file:\n",
    "    vectorizer = pickle.load(vec_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b013ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Preprocess it (same as before)\n",
    "    cleaned = preprocess_text(new_text)  # use your earlier function\n",
    "\n",
    "    # Vectorize\n",
    "    vectorized = vectorizer.transform([cleaned])\n",
    "    \n",
    "    # Predict\n",
    "    predicted_label_int = model.predict(vectorized)[0]\n",
    "    predicted_label_str = le.inverse_transform([predicted_label_int])[0]\n",
    "    return predicted_label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f4b1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Apple Inc. announced on Monday the launch of its latest product, the Apple Vision Pro 2, during its Worldwide Developers Conference (WWDC). The new device boasts an upgraded display resolution, longer battery life, and improved spatial audio features designed to enhance mixed-reality experiences\n",
      "ðŸ“Œ Predicted: TECH\n"
     ]
    }
   ],
   "source": [
    "# Example new headline + description\n",
    "new_text = \"Apple Inc. announced on Monday the launch of its latest product, the Apple Vision Pro 2, during its Worldwide Developers Conference (WWDC). The new device boasts an upgraded display resolution, longer battery life, and improved spatial audio features designed to enhance mixed-reality experiences\"\n",
    "print(f\"Text: {new_text}\")\n",
    "print(f\"ðŸ“Œ Predicted: {predict(new_text)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
